{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1480608,"sourceType":"datasetVersion","datasetId":829369}],"dockerImageVersionId":30648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intro to Deep Learning](https://www.kaggle.com/learn/intro-to-deep-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/overfitting-and-underfitting).**\n\n---","metadata":{"_uuid":"77ee1829-7283-4b3e-b27e-40b0af8866da","_cell_guid":"39c657a8-8b9f-4d52-bddd-3f9522c7fca1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# Introduction #\n\nIn this exercise, youâ€™ll learn how to improve training outcomes by including an early stopping callback to prevent overfitting.\n\nWhen you're ready, run this next cell to set everything up!","metadata":{"_uuid":"3eae2b57-c091-47a3-84a7-21f0e4775c7a","_cell_guid":"fa9dbe0d-c6e2-4d3c-a731-93a3efc27bad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Setup plotting\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('animation', html='html5')\n\n# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning_intro.ex4 import *","metadata":{"_uuid":"c4455672-b51e-4707-aff4-0255320645e2","_cell_guid":"90d4ee1f-a7b7-4e88-bbb6-e7340f2a668d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T02:44:04.193395Z","iopub.execute_input":"2024-11-15T02:44:04.193732Z","iopub.status.idle":"2024-11-15T02:44:05.206116Z","shell.execute_reply.started":"2024-11-15T02:44:04.193704Z","shell.execute_reply":"2024-11-15T02:44:05.204971Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First load the *Spotify* dataset. Your task will be to predict the popularity of a song based on various audio features, like `'tempo'`, `'danceability'`, and `'mode'`.","metadata":{"_uuid":"5477274f-bd77-4b2c-bb97-e039f5765e4f","_cell_guid":"3c5c1c73-f12d-412d-a1b3-9ccdad7f1dc9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.model_selection import GroupShuffleSplit\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\n\nspotify = pd.read_csv('../input/dl-course-data/spotify.csv')\n\nX = spotify.copy().dropna()\ny = X.pop('track_popularity')\nartists = X['track_artist']\n\nfeatures_num = ['danceability', 'energy', 'key', 'loudness', 'mode',\n                'speechiness', 'acousticness', 'instrumentalness',\n                'liveness', 'valence', 'tempo', 'duration_ms']\nfeatures_cat = ['playlist_genre']\n\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n    (OneHotEncoder(), features_cat),\n)\n\n# We'll do a \"grouped\" split to keep all of an artist's songs in one\n# split or the other. This is to help prevent signal leakage.\ndef group_split(X, y, group, train_size=0.75):\n    splitter = GroupShuffleSplit(train_size=train_size)\n    train, test = next(splitter.split(X, y, groups=group))\n    return (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test])\n\nX_train, X_valid, y_train, y_valid = group_split(X, y, artists)\n\nX_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ny_train = y_train / 100 # popularity is on a scale 0-100, so this rescales to 0-1.\ny_valid = y_valid / 100\n\ninput_shape = [X_train.shape[1]]\nprint(\"Input shape: {}\".format(input_shape))","metadata":{"_uuid":"54c02e8a-48c0-453b-a74b-ae34eb15b076","_cell_guid":"46d52025-6810-43cf-a852-4cfadc08ffe0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T02:48:52.620586Z","iopub.execute_input":"2024-11-15T02:48:52.621076Z","iopub.status.idle":"2024-11-15T02:49:06.227424Z","shell.execute_reply.started":"2024-11-15T02:48:52.621046Z","shell.execute_reply":"2024-11-15T02:49:06.226498Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's start with the simplest network, a linear model. This model has low capacity.\n\nRun this next cell without any changes to train a linear model on the *Spotify* dataset.","metadata":{"_uuid":"594fd952-150a-40cf-8302-3e1ce55a4dda","_cell_guid":"97328344-1f23-479e-a31d-8a25b59a347b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(1, input_shape=input_shape),\n])\nmodel.compile(\n    optimizer='adam',\n    loss='mae',\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=50,\n    verbose=0, # suppress output since we'll plot the curves\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()));","metadata":{"_uuid":"e2802bbb-60fb-43f5-ae77-a00ae96d225f","_cell_guid":"9c4ca679-4da2-421b-978f-8bcc89b1c80f","trusted":true,"collapsed":false,"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2024-11-15T03:00:16.244889Z","iopub.execute_input":"2024-11-15T03:00:16.245255Z","iopub.status.idle":"2024-11-15T03:00:25.450866Z","shell.execute_reply.started":"2024-11-15T03:00:16.245226Z","shell.execute_reply":"2024-11-15T03:00:25.449915Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It's not uncommon for the curves to follow a \"hockey stick\" pattern like you see here. This makes the final part of training hard to see, so let's start at epoch 10 instead:","metadata":{"_uuid":"f1a059d7-4e64-40d3-af47-15e812634fb8","_cell_guid":"36960a71-7428-4fe3-a4b3-e061f45deb25","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Start the plot at epoch 10\nhistory_df.loc[10:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()));","metadata":{"_uuid":"60d9d9d6-5a9e-4773-a29e-c96e4d13553c","_cell_guid":"7e8160e3-2d1f-492d-b0c8-97673cee5f98","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:01:32.087401Z","iopub.execute_input":"2024-11-15T03:01:32.088435Z","iopub.status.idle":"2024-11-15T03:01:32.432177Z","shell.execute_reply.started":"2024-11-15T03:01:32.088384Z","shell.execute_reply":"2024-11-15T03:01:32.431312Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1) Evaluate Baseline\n\nWhat do you think? Would you say this model is underfitting, overfitting, just right?","metadata":{"_uuid":"361bd264-1eca-4bf2-9353-8eaa2cf3d302","_cell_guid":"20ece4fd-24e9-4532-8c2a-c3de7000c594","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_1.check()","metadata":{"_uuid":"eed92ddf-019b-452f-8dce-2ea432c88e7b","_cell_guid":"ad2916d4-9614-4bd3-8c9f-07df24f56c0f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:01:46.477754Z","iopub.execute_input":"2024-11-15T03:01:46.478585Z","iopub.status.idle":"2024-11-15T03:01:46.485655Z","shell.execute_reply.started":"2024-11-15T03:01:46.478552Z","shell.execute_reply":"2024-11-15T03:01:46.484723Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's add some capacity to our network. We'll add three hidden layers with 128 units each. Run the next cell to train the network and see the learning curves.","metadata":{"_uuid":"8f041b7a-05d7-4280-ad70-0e7e79ec22c2","_cell_guid":"9c32bf59-49f3-4b08-9f90-6837dee31107","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=input_shape),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n])\nmodel.compile(\n    optimizer='adam',\n    loss='mae',\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=50,\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()));","metadata":{"_uuid":"971fb6d4-36b7-4256-9d0b-86698f1e8e86","_cell_guid":"689315dc-4262-4e9d-8bd1-08eeeaba636a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:02:56.798113Z","iopub.execute_input":"2024-11-15T03:02:56.799108Z","iopub.status.idle":"2024-11-15T03:03:07.912682Z","shell.execute_reply.started":"2024-11-15T03:02:56.799073Z","shell.execute_reply":"2024-11-15T03:03:07.911616Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2) Add Capacity\n\nWhat is your evaluation of these curves? Underfitting, overfitting, just right?","metadata":{"_uuid":"d2797005-f59a-4a25-aafa-7329cc4603c7","_cell_guid":"2b225c5e-5ceb-4931-9cc0-9d701493d154","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_2.check()","metadata":{"_uuid":"7d51212e-b786-4ec2-b620-45b1a5505aa4","_cell_guid":"1616ee97-91ce-4ff5-80b7-6fcf2b62fea2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:03:27.386227Z","iopub.execute_input":"2024-11-15T03:03:27.387066Z","iopub.status.idle":"2024-11-15T03:03:27.394446Z","shell.execute_reply.started":"2024-11-15T03:03:27.387032Z","shell.execute_reply":"2024-11-15T03:03:27.393505Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3) Define Early Stopping Callback\n\nNow define an early stopping callback that waits 5 epochs (`patience'`) for a change in validation loss of at least `0.001` (`min_delta`) and keeps the weights with the best loss (`restore_best_weights`).","metadata":{"_uuid":"8a4ff177-fd42-4641-92a1-28bdd3bb311f","_cell_guid":"2ca77097-1af8-49d4-bf7e-a10e0ea233bd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from tensorflow.keras import callbacks\n\n# YOUR CODE HERE: define an early stopping callback\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001,\n    patience=5,\n    restore_best_weights=True\n)\n\n# Check your answer\nq_3.check()","metadata":{"_uuid":"fa344c58-6229-4575-bdde-fda611c0fac1","_cell_guid":"5f0f5eaa-9f9d-470d-9b6e-35937d99b1da","trusted":true,"collapsed":false,"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2024-11-15T03:09:13.744407Z","iopub.execute_input":"2024-11-15T03:09:13.745110Z","iopub.status.idle":"2024-11-15T03:09:13.753379Z","shell.execute_reply.started":"2024-11-15T03:09:13.745078Z","shell.execute_reply":"2024-11-15T03:09:13.752479Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_3.hint()\n#q_3.solution()","metadata":{"_uuid":"14b990b4-b4d5-4f44-bbf2-ccd19ce61167","_cell_guid":"b2f84423-8e5e-4798-b8ff-3922fe086dab","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now run this cell to train the model and get the learning curves. Notice the `callbacks` argument in `model.fit`.","metadata":{"_uuid":"6b952cd8-158c-413c-a9b6-e43bac8e4216","_cell_guid":"5d76e3bd-26af-49dc-be58-9844575d85c0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=input_shape),\n    layers.Dense(64, activation='relu'),    \n    layers.Dense(1)\n])\nmodel.compile(\n    optimizer='adam',\n    loss='mae',\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=50,\n    callbacks=[early_stopping]\n)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()));","metadata":{"_uuid":"ac0d2019-4490-4eb1-a164-f24cd84a8ff1","_cell_guid":"deaaa47f-7e71-44ae-9e55-3a9342fa5dd3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:09:38.867054Z","iopub.execute_input":"2024-11-15T03:09:38.867718Z","iopub.status.idle":"2024-11-15T03:09:42.492159Z","shell.execute_reply.started":"2024-11-15T03:09:38.867683Z","shell.execute_reply":"2024-11-15T03:09:42.491171Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4) Train and Interpret\n\nWas this an improvement compared to training without early stopping?","metadata":{"_uuid":"92acfb3a-5f8f-4135-9b4d-cac15786cb3d","_cell_guid":"bba41bcf-1038-4d25-9661-b3ae79144c27","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_4.check()","metadata":{"_uuid":"217bad82-6e7d-4422-b2db-21e6454ae7b9","_cell_guid":"ae1ffe5f-9c48-4902-8506-d5aa274548fa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-15T03:09:54.104803Z","iopub.execute_input":"2024-11-15T03:09:54.105169Z","iopub.status.idle":"2024-11-15T03:09:54.113227Z","shell.execute_reply.started":"2024-11-15T03:09:54.105140Z","shell.execute_reply":"2024-11-15T03:09:54.112288Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you like, try experimenting with `patience` and `min_delta` to see what difference it might make.\n\n# Keep Going #\n\nMove on to [**learn about a couple of special layers**](https://www.kaggle.com/ryanholbrook/dropout-and-batch-normalization): batch normalization and dropout.","metadata":{"_uuid":"c151b5f0-b379-4184-93e5-f56e60599fd0","_cell_guid":"abc3cbd6-1cad-4bd8-8999-82143f22e2bf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*","metadata":{"_uuid":"0e504bee-54ee-411f-9dce-7cc14ef50c48","_cell_guid":"a6876a37-3ec8-49c4-b439-ac21a36849b4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}